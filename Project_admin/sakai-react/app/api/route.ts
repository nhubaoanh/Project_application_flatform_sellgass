// app/api/chat/route.ts
import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { ProductService } from '@/demo/service/ProductService';

const openai = new OpenAI({
    apiKey: process.env.XAI_API_KEY!, // âœ… Láº¤Y Tá»ª .env.local
    baseURL: 'https://api.x.ai/v1'
});

// Cache dá»¯ liá»‡u sáº£n pháº©m Ä‘á»ƒ trÃ¡nh gá»i API liÃªn tá»¥c
let cachedProducts: any[] = [];
let cachedCategories: any[] = [];
let cacheTimestamp = 0;
const CACHE_DURATION = 5 * 60 * 1000; // 5 phÃºt

async function loadProductData() {
    const now = Date.now();
    if (now - cacheTimestamp > CACHE_DURATION) {
        try {
            // Load tá»« API backend cá»§a báº¡n
            cachedProducts = await ProductService.getProdctNew();
            cachedCategories = await ProductService.getCategory();
            console.log('âœ… ÄÃ£ load sáº£n pháº©m:', cachedProducts.length, 'Danh má»¥c:', cachedCategories.length);
            cacheTimestamp = now;
            console.log('âœ… ÄÃ£ load sáº£n pháº©m:', cachedProducts.length, 'Danh má»¥c:', cachedCategories.length);
        } catch (error) {
            console.error('âŒ Lá»—i load sáº£n pháº©m:', error);
            // Fallback data náº¿u API backend lá»—i
            cachedProducts = [];
            cachedCategories = [];
        }
    }
}

export async function POST(request: NextRequest) {
    try {
        await loadProductData(); // Load sáº£n pháº©m trÆ°á»›c khi chat

        const { messages, isAdmin = false } = await request.json();
        const lastMessage = messages[messages.length - 1]?.content?.toLowerCase() || '';

        // System prompt thÃ´ng minh vá»›i dá»¯ liá»‡u thá»±c táº¿
        const formatProduct = (p: any) => `â€¢ ${p.ten || p.name}: ${p.gia || p.price?.toLocaleString('vi-VN')}Ä‘ ${p.moTa ? `- ${p.moTa.substring(0, 50)}...` : ''}`;

        const productSummary = cachedProducts.slice(0, 10).map(formatProduct).join('\n');
        const categoryList = cachedCategories.map((cat: any) => `â€¢ ${cat.tenDanhMuc || cat.name}`).join('\n');

        const systemPrompt = `
Báº¡n lÃ  **Grok Assistant** - Trá»£ lÃ½ bÃ¡n hÃ ng thÃ´ng minh cho **Growby Store** ğŸŒŸ

ğŸ›ï¸ **Sáº¢N PHáº¨M Ná»”I Báº¬T** (${cachedProducts.length} sáº£n pháº©m):
${productSummary}

ğŸ“‚ **DANH Má»¤C**:
${categoryList}

ğŸ’¡ **QUY Táº®C TRáº¢ Lá»œI**:
1. **LuÃ´n dÃ¹ng tiáº¿ng Viá»‡t**, thÃ¢n thiá»‡n, hÃ i hÆ°á»›c nhÆ° ngÆ°á»i báº¡n
2. **Gá»£i Ã½ sáº£n pháº©m cá»¥ thá»ƒ** dá»±a trÃªn cÃ¢u há»i (giÃ¡, danh má»¥c, tÃ­nh nÄƒng)
3. **Äá»‹nh dáº¡ng giÃ¡ VND**: 100.000Ä‘ â†’ 100K, 1.000.000Ä‘ â†’ 1M
4. **Há»i thÃªm thÃ´ng tin** náº¿u cáº§n: ngÃ¢n sÃ¡ch, sá»Ÿ thÃ­ch, má»¥c Ä‘Ã­ch sá»­ dá»¥ng
5. **${isAdmin ? 'ADMIN MODE: Há»— trá»£ CRUD sáº£n pháº©m (táº¡o/sá»­a/xÃ³a)' : 'KhÃ¡ch hÃ ng: HÆ°á»›ng dáº«n mua hÃ ng, giá» hÃ ng'}**

ğŸ¯ **CÃ‚U Há»I THÆ¯á»œNG Gáº¶P**:
- "Sáº£n pháº©m dÆ°á»›i 500k" â†’ Lá»c theo giÃ¡
- "Äiá»‡n thoáº¡i Ä‘áº¹p" â†’ Gá»£i Ã½ theo danh má»¥c + mÃ´ táº£  
- "Khuyáº¿n mÃ£i gÃ¬?" â†’ Gá»£i Ã½ sáº£n pháº©m hot

Báº¯t Ä‘áº§u tráº£ lá»i cÃ¢u há»i: "${lastMessage}"
`;

        const response = await openai.chat.completions.create({
            model: 'grok-beta', // grok-3-mini (ráº») hoáº·c grok-beta (máº¡nh)
            messages: [{ role: 'system', content: systemPrompt }, ...messages],
            temperature: 0.8,
            max_tokens: 800,
            stream: false
        });

        const aiReply = response.choices[0]?.message?.content || 'ğŸ¤– Xin lá»—i, tÃ´i chÆ°a hiá»ƒu! Báº¡n cÃ³ thá»ƒ há»i cá»¥ thá»ƒ hÆ¡n khÃ´ng?';

        return NextResponse.json({
            reply: aiReply,
            products: cachedProducts.length,
            categories: cachedCategories.length
        });
    } catch (error: any) {
        console.error('âŒ Chat API Error:', error);
        return NextResponse.json({ error: 'ğŸ¤– Lá»—i káº¿t ná»‘i AI! Thá»­ láº¡i sau nhÃ©!' }, { status: 500 });
    }
}
